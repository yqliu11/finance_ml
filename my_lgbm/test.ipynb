{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from my.data.basic_func import get_basic_data\n",
    "from my.data.meta_api import get_before_trade_info\n",
    "from datetime import time as dtime\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(start_dt, end_dt):\n",
    "    table_name = \"bond_calendar\"\n",
    "    df = get_basic_data(20230728, table_name)\n",
    "    cal_list = df[df.exchmarket == \"NIB\"].trade_dt\n",
    "    dates = []\n",
    "    for i in cal_list:\n",
    "        if (int(i) >= start_dt) & (int(i) <= end_dt):\n",
    "            dates.append(int(i))\n",
    "    dates_not_in = [ 20220129, 20220130, 20221107, 20221202, 20221216,\n",
    "        20221219, 20221231, 20230120, 20230128, 20230129, 20230215, 20230216,  20230410, 20230423, 20230506, 20230517, 20230625]\n",
    "    for j in dates_not_in:\n",
    "        if j in dates:\n",
    "            dates.remove(j)\n",
    "    return dates\n",
    "\n",
    "\n",
    "def resample(df, period):\n",
    "    # period = 60s\n",
    "    df = df.resample(period).last()\n",
    "    return df\n",
    "\n",
    "\n",
    "def label(series, method):\n",
    "    if method == \"logdiff\":\n",
    "        return np.log(series).diff() * 1e4\n",
    "    if method == \"diff\":\n",
    "        return np.diff(series)\n",
    "\n",
    "\n",
    "def clean_ourliers(df):\n",
    "    df[df[\"ylabel\"] > 10] = 0  # clean outliers\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def read_data(start_dt, end_dt):\n",
    "    dates = get_dates(start_dt, end_dt)\n",
    "    import factors\n",
    "    df = factors.get_factors('220220.IB', 20230418)  # to get the shape of factors\n",
    "    a, b = np.shape(df)\n",
    "    Fx = np.zeros((len(dates), 300, b))  # 300 mins every day a= 300\n",
    "    Fy = np.zeros((len(dates), 300))\n",
    "    for i in range(len(dates)):\n",
    "        date = dates[i]\n",
    "        # print(date)\n",
    "        df_mc = get_before_trade_info(date, \"bond_main_contract\")\n",
    "        mc_dict = dict(zip(df_mc.label, df_mc.securityid))\n",
    "        if \"CDB10Y01.IB\" in mc_dict:\n",
    "            bond_code = mc_dict[\"CDB10Y01.IB\"]\n",
    "        else:\n",
    "            bond_code = \"220220.IB\"\n",
    "        df = factors.get_factors(bond_code, date)\n",
    "        # df = df.resample(\"60s\").last()\n",
    "        df[\"ylabel\"] = label(df[\"midprice\"], \"logdiff\")\n",
    "        # delete data between 11:30 and 13:30\n",
    "        df = df.drop(df[(df.index.time >= dtime(11, 30, 00)) & (df.index.time < dtime(13, 30, 00))].index)\n",
    "        df[\"mins\"] = [i for i in range(len(df))]\n",
    "        Fy[i, :] = df.ylabel\n",
    "        del df[\"ylabel\"]\n",
    "        del df[\"midprice\"]\n",
    "        Fx[i, :] = df\n",
    "    return Fx, Fy\n",
    "\n",
    "\n",
    "def split(Fx, Fy, period, dates):\n",
    "    kk = round(len(dates)/period)\n",
    "    a, b, c= np.shape(Fx)\n",
    "    train_xlist = np.zeros((kk, period*300, c))\n",
    "    train_ylist = np.zeros((kk, period*300))\n",
    "    test_xlist = np.zeros((kk, 300, c))\n",
    "    test_ylist = np.zeros((kk, 300))\n",
    "\n",
    "    for i in range(kk):\n",
    "        train = list(range(i, period+i))\n",
    "        train_x = np.vstack(Fx[train,:])\n",
    "        train_y = np.hstack(Fy[train,:])\n",
    "        test_x = Fx[period+i]\n",
    "        test_y = Fy[period+i]\n",
    "        train_xlist[i, :, :] = train_x\n",
    "        train_ylist[i, : ] = train_y\n",
    "        test_xlist[i,:,:] = test_x\n",
    "        test_ylist[i,:] = test_y\n",
    "    return train_xlist, train_ylist, test_xlist, test_ylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fx, Fy = read_data(20220101,20221231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = 20220101\n",
    "end_dt = 20221231\n",
    "dates = get_dates(start_dt, end_dt)\n",
    "# train_xlist, train_ylist, test_xlist, test_ylist = split(Fx, Fy, 200, dates)\n",
    "\n",
    "period = 100\n",
    "\n",
    "kk = len(dates) - period -1 \n",
    "a, b, c= np.shape(Fx)\n",
    "train_xlist = np.zeros((kk, period*300, c))\n",
    "train_ylist = np.zeros((kk, period*300))\n",
    "test_xlist = np.zeros((kk, 300, c))\n",
    "test_ylist = np.zeros((kk, 300))\n",
    "\n",
    "for i in range(kk):\n",
    "    train = list(range(i, period+i))\n",
    "    train_x = np.vstack(Fx[train,:])\n",
    "    train_y = np.hstack(Fy[train,:])\n",
    "    test_x = Fx[period+i]\n",
    "    test_y = Fy[period+i]\n",
    "    # delete nan or infs\n",
    "    train_y[(train_y>100) |  (train_y<-100)] = 0\n",
    "    train_y[np.isnan(train_y)] = 0\n",
    "\n",
    "    test_y[(test_y>100) |  (test_y<-100)] = 0\n",
    "    test_y[np.isnan(test_y)] = 0\n",
    "\n",
    "    train_xlist[i, :, :] = train_x\n",
    "    train_ylist[i, : ] = train_y\n",
    "    test_xlist[i,:,:] = test_x\n",
    "    test_ylist[i,:] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "X_train = train_xlist[i]\n",
    "X_test = test_xlist[i]\n",
    "y_train = train_ylist[i]\n",
    "y_test = test_ylist[i]\n",
    "# y_train = y_train.ravel()\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.107133\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000009 seconds, init for row-wise cost 0.002598 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2457\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.000691\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 100 and max_depth = 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.05, n_estimators=20, num_leaves=100,\n",
       "              objective='regression', verbosity=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = lgb.LGBMRegressor(objective=\"regression\", num_leaves=100, learning_rate=0.05, n_estimators=20, verbosity=2)\n",
    "my_model.fit(X_train, y_train, verbose=False)\n",
    "# my_model.fit(train_X[1].transpose(), train_y[1], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 0.24564963122662004\n"
     ]
    }
   ],
   "source": [
    "predictions = my_model.predict(X_test)\n",
    "# 对模型的预测结果进行评判（平均绝对误差）\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(10,8))\n",
    "ax[0].plot(y_test,'.',color='r')\n",
    "ax[0].set_ylabel('Y_test',fontsize=14)\n",
    "ax[0].set_title(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))\n",
    "ax[1].plot(predictions,'.')\n",
    "ax[1].set_ylabel('y_predictions',fontsize=14)\n",
    "fig.savefig('regression.jpg', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    # 参数网格\n",
    "    param_grid = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 0.95, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 0.95, step=0.1),\n",
    "        \"random_state\": 2021,\n",
    "    }\n",
    "    # 5折交叉验证\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # LGBM建模\n",
    "        model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric=\"binary_logloss\",\n",
    "            early_stopping_rounds=100,\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, \"binary_logloss\")\n",
    "            ],\n",
    "        )\n",
    "        # 模型预测\n",
    "        preds = model.predict_proba(X_test)\n",
    "        # 优化指标logloss最小\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Regression\")\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参训练\n",
    "def lgb_optuna(trial, train_x, train_y, test_x, test_y):\n",
    "    param = {\n",
    "        'num_leaves': trial.suggest_int(\n",
    "            'num_leaves', 10, 1000\n",
    "        ),\n",
    "        'max_bin':100,\n",
    "        'min_data_in_leaf': trial.suggest_int(\n",
    "            'min_data_in_leaf', 100, 1000\n",
    "        ),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        'bagging_fraction': trial.suggest_float(\"bagging_fraction\", 0.2, 0.95, step=0.1),\n",
    "        'bagging_freq':5,\n",
    "        'bagging_seed':66,\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 0.95, step=0.1),\n",
    "        'feature_fraction_seed': 66,\n",
    "        # loss\n",
    "        'lambda_l1': trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        'lambda_l2': trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        'min_gain_to_split': trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        # greedy\n",
    "        'min_sum_hessian_in_leaf':   trial.suggest_discrete_uniform(\n",
    "            'min_sum_hessian_in_leaf', 0.55 , 20.0, 0.1\n",
    "        ),\n",
    "        # object-metric\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'n_jobs':25,\n",
    "        'boosting': 'gbdt',\n",
    "        'verbose': 1,\n",
    "        'early_stopping_rounds':50,\n",
    "        'n_estimators': 500\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**param)  \n",
    "    model.fit(train_x,  train_y,\n",
    "            eval_set=[\n",
    "                (train_x,  train_y), (test_x, test_y)\n",
    "            ],\n",
    "            early_stopping_rounds=50,     \n",
    "            verbose=200\n",
    "            )\n",
    "    pred_ = model.predict(test_x)\n",
    "    loss = np.sqrt(mean_squared_error(test_x, np.round(np.expm1(pred_))))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# my_model = lgb.LGBMRegressor(objective=\"regression\", num_leaves=10, learning_rate=0.1, n_estimators=20, verbosity=2)\n",
    "# my_model.fit(X_train, y_train, verbose=False)\n",
    "# # my_model.fit(train_X[1].transpose(), train_y[1], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-11 17:26:32,649] A new study created in memory with name: no-name-3da412c6-6c7e-4072-b7da-a3e06e16a7ea\n",
      "[W 2023-08-11 17:26:32,755] Trial 0 failed with parameters: {'num_leaves': 953, 'min_data_in_leaf': 316, 'learning_rate': 0.2672123342757945, 'bagging_fraction': 0.2, 'feature_fraction': 0.7, 'lambda_l2': 70, 'min_gain_to_split': 8.240949845588299, 'min_sum_hessian_in_leaf': 17.450000000000003} because of the following error: ValueError('y_true and y_pred have different number of output (10!=1)').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/liuyuqing/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-12-1a2536615963>\", line 2, in <lambda>\n",
      "    func = lambda trial: lgb_optuna(trial, X_train, y_train, X_test, y_test)\n",
      "  File \"<ipython-input-10-2aa04ba8c903>\", line 44, in lgb_optuna\n",
      "    loss = np.sqrt(mean_squared_error(test_x, np.round(np.expm1(pred_))))\n",
      "  File \"/usr/local/python3.8.10/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/python3.8.10/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 255, in mean_squared_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/usr/local/python3.8.10/lib/python3.8/site-packages/sklearn/metrics/_regression.py\", line 95, in _check_reg_targets\n",
      "    raise ValueError(\"y_true and y_pred have different number of output \"\n",
      "ValueError: y_true and y_pred have different number of output (10!=1)\n",
      "[W 2023-08-11 17:26:32,757] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.240949845588299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.240949845588299\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=316, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=316\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17.450000000000003, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17.450000000000003\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.240949845588299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.240949845588299\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17.450000000000003, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17.450000000000003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=316, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=316\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 999\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.240949845588299, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.240949845588299\n",
      "[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=316, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=316\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=17.450000000000003, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=17.450000000000003\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Start training from score -0.000691\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's rmse: 0.489613\tvalid_1's rmse: 0.361278\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (10!=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1a2536615963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlgb_optuna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[0;32m--> 442\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1a2536615963>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlgb_optuna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2aa04ba8c903>\u001b[0m in \u001b[0;36mlgb_optuna\u001b[0;34m(trial, train_x, train_y, test_x, test_y)\u001b[0m\n\u001b[1;32m     42\u001b[0m             )\n\u001b[1;32m     43\u001b[0m     \u001b[0mpred_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.8.10/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.8.10/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    256\u001b[0m         y_true, y_pred, multioutput)\n\u001b[1;32m    257\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.8.10/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[0m\u001b[1;32m     96\u001b[0m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of output (10!=1)"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "func = lambda trial: lgb_optuna(trial, X_train, y_train, X_test, y_test)\n",
    "study.optimize(func, n_trials=10)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
